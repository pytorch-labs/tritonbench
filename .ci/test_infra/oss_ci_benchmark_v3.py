"""
Convert Tritonbench json to ClickHouse oss_ci_benchmark_v3 schema.
https://github.com/pytorch/test-infra/blob/main/clickhouse_db_schema/oss_ci_benchmark_v3/schema.sql
"""

import argparse
import json
import re
from pathlib import Path

from typing import Any, Dict, List, Tuple

def parse_dependencies(envs: Dict[str, str]) -> Dict[str, Dict[str, Any]]:
    dependencies = {
        "pytorch": "pytorch/pytorch",
        "triton": "triton-lang/triton",
        "tritonbench": "pytorch-labs/tritonbench",
    }
    out = {}
    for dep in dependencies:
        out[dep] = {}
        out[dep]["repo"] = dependencies[dep]
        out[dep]["branch"] = envs[f"{dep}_branch"]
        out[dep]["sha"] = envs[f"{dep}_commit"]
        out[dep]["extra_info"] = {}
        out[dep]["extra_info"]["commit_time"] = envs[f"{dep}_commit_time"]
    return out


def parse_metric_id(metric_id: str) -> Tuple[str, str, str, str, str]:
    print(metric_id)
    # per-input metric
    if ("[x_" in metric_id):
        metric_id_regex = (
            r"tritonbench_([0-9a-z_]+)_([a-z_]+)\[x_(.*)-([0-9a-z_]+)\]_([a-z_]+)"
        )
        op, mode, input, backend, metric = re.match(metric_id_regex, metric_id).groups()
        out = (op, mode, input, backend, metric)
        return out
    # aggregated metric
    input = None
    metric_id_regex = r"tritonbench_([0-9a-z_]+)_([a-z_]+)\[([0-9a-z_]+)\]-(.+)"
    op, mode, backend, metric = re.search(metric_id_regex, metric_id).groups()
    return (op, mode, input, backend, metric)

def generate_oss_ci_benchmark_v3_json(
        benchmark_result: Dict[str, Any],
) -> List[Dict[str, Any]]:
    """
    Parse Benchmark Json and return a list of entries
    """
    common = {}
    out = []
    for metric_id in benchmark_result["metrics"]:
        # bypass if the metric is a target value
        if metric_id.endswith("-target"):
            continue
        entry = common.copy()
        entry["dependencies"] = parse_dependencies(benchmark_result["env"])
        op, mode, _input, backend, metric_name = parse_metric_id(metric_id)
        metric_value = benchmark_result["metrics"][metric_id]
        entry["benchmark"] = {
            "name": benchmark_result["name"],
            "mode": mode,
            "dtype": "unknown",
            "extra_info": {},
        }
        # We use the model field for operator
        entry["model"] = {
            "name": op,
            "type": "tritonbench-oss",
            "backend": backend,
        }
        entry["metric"] = {
            "name": metric_name,
            "benchmark_values": [metric_value],
        }
        out.append(entry)
    return out

def v3_json_to_str(v3_json: List[Dict[str, Any]], to_lines: bool = True) -> str:
    if to_lines:
        entry_list = [json.dumps(entry) for entry in v3_json]
        return "\n".join(entry_list)
    else:
        return json.dumps(v3_json, indent=4)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--json",
        required=True,
        help="Upload benchmark result json file.",
    )
    parser.add_argument("--output",required=True,help="output json.")
    args = parser.parse_args()
    upload_file_path = Path(args.json)
    assert (
        upload_file_path.exists()
    ), f"Specified result json path {args.json} does not exist."
    with open(upload_file_path, "r") as fp:
        benchmark_result = json.load(fp)
    oss_ci_v3_json = generate_oss_ci_benchmark_v3_json(benchmark_result)
    out_str = v3_json_to_str(oss_ci_v3_json)
    output_dir = Path(args.output).parent
    output_dir.mkdir(parents=True, exist_ok=True)
    with open(args.output, "w") as fp:
        fp.write(out_str)
    print(f"[oss_ci_benchmark_v3] Successfully saved to {args.output}")
